{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5917af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24adb8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Initialize Tesseract path\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# 2. Load Roberta model\n",
    "def load_model(model_path=\"roberta_spam_model.pt\", base_model=\"roberta-base\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(base_model, num_labels=2)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return tokenizer, model\n",
    "\n",
    "tokenizer, model = load_model()\n",
    "\n",
    "# 3. Load and preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise Exception(f\"Image not found at {image_path}\")\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "# 4. Extract text via OCR\n",
    "def extract_text_from_image(image):\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text.strip()\n",
    "\n",
    "# 5. Classify text using Roberta\n",
    "def classify_text(text, tokenizer, model, max_length=128):\n",
    "    encoded_inputs = tokenizer(text, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_inputs)\n",
    "    probs = torch.softmax(outputs.logits, dim=1)\n",
    "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return {\n",
    "        'text': text,\n",
    "        'prediction': 'Spam' if prediction == 1 else 'Ham',\n",
    "        'spam_probability': probs[0][1].item(),\n",
    "        'ham_probability': probs[0][0].item()\n",
    "    }\n",
    "\n",
    "# 6. Main Function\n",
    "def main(image_path):\n",
    "    try:\n",
    "        image = preprocess_image(image_path)\n",
    "        ocr_text = extract_text_from_image(image)\n",
    "        \n",
    "        if not ocr_text:\n",
    "            print(\"No text detected in image.\")\n",
    "            return\n",
    "        \n",
    "        result = classify_text(ocr_text, tokenizer, model)\n",
    "        \n",
    "        print(f\"\\nExtracted Text:\\n{result['text']}\")\n",
    "        print(f\"Prediction: {result['prediction']}\")\n",
    "        print(f\"Spam Probability: {result['spam_probability']:.4f}\")\n",
    "        print(f\"Ham Probability: {result['ham_probability']:.4f}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# 7. Run\n",
    "if __name__ == \"__main__\":\n",
    "    img_path = r\"C:\\Users\\jhanv\\bd1\\fda\\test_image2.jpg\"\n",
    "    main(img_path)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
